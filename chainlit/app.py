"""
HKEX Agent - Chainlit Web Interface

æ¸¯è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ Web ç•Œé¢ï¼ŒåŸºäº Chainlit æ„å»ºã€‚
æ”¯æŒå¯¹è¯å†å²æŒä¹…åŒ–ã€ç”¨æˆ·é…ç½®å’Œæ¢å¤ã€‚
"""

import json
import os
import re
import sys
from pathlib import Path
from typing import Optional

# è·å–é¡¹ç›®æ ¹ç›®å½•
project_root = Path(__file__).parent.parent.resolve()

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(project_root))

# åˆ‡æ¢å·¥ä½œç›®å½•åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼Œç¡®ä¿ç›¸å¯¹è·¯å¾„æ­£ç¡®è§£æ
# è¿™æ · mcp_config.jsonã€pdf_cache/ ç­‰è·¯å¾„éƒ½èƒ½æ­£å¸¸å·¥ä½œ
os.chdir(project_root)

import chainlit as cl
from chainlit.data.sql_alchemy import SQLAlchemyDataLayer
from chainlit.input_widget import Select, Slider, Switch, TextInput
from langchain_core.messages import HumanMessage, AIMessage

from src.agents.main_agent import create_hkex_agent
from local_storage import LocalStorageClient
from config_models import (
    UserConfig,
    APIProvider,
    MODEL_PRESETS,
    CONFIG_PRESETS,
    DEFAULT_SYSTEM_PROMPT,
    get_default_config,
    get_models_for_provider,
    get_preset_options,
)
from config_storage import get_config_storage, init_config_storage

# ============== æ•°æ®æŒä¹…åŒ–é…ç½® ==============
# ä½¿ç”¨ SQLite å­˜å‚¨å¯¹è¯å†å²
DB_PATH = project_root / "chainlit_data" / "chat_history.db"
STORAGE_PATH = project_root / "chainlit_data" / "files"
DB_PATH.parent.mkdir(parents=True, exist_ok=True)
STORAGE_PATH.mkdir(parents=True, exist_ok=True)

# åˆ›å»ºæœ¬åœ°å­˜å‚¨å®¢æˆ·ç«¯
storage_client = LocalStorageClient(storage_dir=STORAGE_PATH)

# åˆå§‹åŒ–é…ç½®å­˜å‚¨
config_storage = get_config_storage(DB_PATH)


# ============== æ–‡ä»¶ä¸‹è½½åŠŸèƒ½ ==============
async def check_and_send_file_download(tool_output: str, tool_name: str) -> None:
    """æ£€æµ‹å·¥å…·è¾“å‡ºä¸­çš„æ–‡ä»¶è·¯å¾„å¹¶æä¾›ä¸‹è½½é“¾æ¥ã€‚
    
    æ”¯æŒçš„æ–‡ä»¶ç±»å‹ï¼š
    - Markdown (.md)
    - PDF (.pdf)
    - JSON (.json)
    - æ–‡æœ¬ (.txt)
    """
    # åŒ¹é…å¸¸è§æ–‡ä»¶è·¯å¾„æ¨¡å¼
    # æ”¯æŒ /md/xxx.md, /pdf_cache/xxx.pdf, ./xxx.md ç­‰æ ¼å¼
    file_patterns = [
        r'(/md/[^\s\'"]+\.md)',  # /md/ ç›®å½•ä¸‹çš„ markdown
        r'(/pdf_cache/[^\s\'"]+\.(?:pdf|txt|json))',  # pdf_cache ç›®å½•
        r'(\.?/[\w\-/]+\.(?:md|pdf|txt|json))',  # ç›¸å¯¹è·¯å¾„
        r'([A-Za-z]:\\[^\s\'"]+\.(?:md|pdf|txt|json))',  # Windows ç»å¯¹è·¯å¾„
        r'(/[^\s\'"]+\.(?:md|pdf|txt|json))',  # Unix ç»å¯¹è·¯å¾„
    ]
    
    found_files = set()
    for pattern in file_patterns:
        matches = re.findall(pattern, tool_output)
        found_files.update(matches)
    
    for file_path in found_files:
        # è½¬æ¢è™šæ‹Ÿè·¯å¾„åˆ°å®é™…è·¯å¾„
        if file_path.startswith('/md/'):
            actual_path = project_root / 'md' / file_path[4:]
        elif file_path.startswith('/pdf_cache/'):
            actual_path = project_root / 'pdf_cache' / file_path[11:]
        elif file_path.startswith('./'):
            actual_path = project_root / file_path[2:]
        elif file_path.startswith('/'):
            # æ£€æŸ¥æ˜¯å¦æ˜¯é¡¹ç›®å†…çš„ç»å¯¹è·¯å¾„
            if str(project_root) in file_path:
                actual_path = Path(file_path)
            else:
                actual_path = project_root / file_path[1:]
        else:
            actual_path = project_root / file_path
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if actual_path.exists() and actual_path.is_file():
            try:
                # åˆ›å»º Chainlit æ–‡ä»¶å…ƒç´ 
                file_name = actual_path.name
                
                # æ ¹æ®æ–‡ä»¶ç±»å‹è®¾ç½® MIME ç±»å‹
                mime_types = {
                    '.md': 'text/markdown',
                    '.pdf': 'application/pdf',
                    '.json': 'application/json',
                    '.txt': 'text/plain',
                }
                mime_type = mime_types.get(actual_path.suffix.lower(), 'application/octet-stream')
                
                # å‘é€æ–‡ä»¶ä¸‹è½½é“¾æ¥
                elements = [
                    cl.File(
                        name=file_name,
                        path=str(actual_path),
                        display="inline",
                    )
                ]
                
                await cl.Message(
                    content=f"ğŸ“ **æ–‡ä»¶å·²ç”Ÿæˆ**: `{file_name}`\n\nç‚¹å‡»ä¸‹æ–¹é“¾æ¥ä¸‹è½½ï¼š",
                    elements=elements,
                ).send()
                
            except Exception as e:
                print(f"[WARN] Failed to create download link for {actual_path}: {e}")


@cl.data_layer
def get_data_layer():
    """é…ç½® SQLite æ•°æ®æŒä¹…åŒ–å±‚ï¼ˆå¸¦æœ¬åœ°æ–‡ä»¶å­˜å‚¨ï¼‰ã€‚"""
    return SQLAlchemyDataLayer(
        conninfo=f"sqlite+aiosqlite:///{DB_PATH}",
        storage_provider=storage_client,
    )


# ============== ç®€å•ç”¨æˆ·è®¤è¯ ==============
@cl.password_auth_callback
def auth_callback(username: str, password: str):
    """
    ç®€å•å¯†ç è®¤è¯ã€‚
    
    é»˜è®¤ç”¨æˆ·ï¼š
    - ç”¨æˆ·å: admin, å¯†ç : admin (ç®¡ç†å‘˜)
    - ç”¨æˆ·å: user, å¯†ç : user (æ™®é€šç”¨æˆ·)
    """
    # ç®€å•ç”¨æˆ·éªŒè¯
    if (username, password) == ("admin", "admin"):
        return cl.User(
            identifier="admin", 
            metadata={"role": "ADMIN", "provider": "credentials"}
        )
    elif (username, password) == ("user", "user"):
        return cl.User(
            identifier="user", 
            metadata={"role": "USER", "provider": "credentials"}
        )
    else:
        return None


# ============== é…ç½®è¾…åŠ©å‡½æ•° ==============
def create_model_from_config(config: UserConfig):
    """æ ¹æ®ç”¨æˆ·é…ç½®åˆ›å»ºæ¨¡å‹å®ä¾‹.
    
    Args:
        config: ç”¨æˆ·é…ç½®å¯¹è±¡
        
    Returns:
        LangChain Chat æ¨¡å‹å®ä¾‹
    """
    # è·å– API Keyï¼ˆä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é…ç½®ï¼Œå¦åˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰
    if config.provider == APIProvider.SILICONFLOW.value:
        api_key = config.api_key_override or os.environ.get("SILICONFLOW_API_KEY")
        if not api_key:
            raise ValueError("æœªé…ç½® SiliconFlow API Key")
        
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(
            model=config.model,
            base_url="https://api.siliconflow.cn/v1",
            api_key=api_key,
            temperature=config.temperature,
            max_tokens=config.max_tokens,
            top_p=config.top_p,
            frequency_penalty=config.frequency_penalty,
            presence_penalty=config.presence_penalty,
        )
    
    elif config.provider == APIProvider.OPENAI.value:
        api_key = config.api_key_override or os.environ.get("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("æœªé…ç½® OpenAI API Key")
        
        from langchain_openai import ChatOpenAI
        return ChatOpenAI(
            model=config.model,
            api_key=api_key,
            temperature=config.temperature,
            max_tokens=config.max_tokens,
            top_p=config.top_p,
            frequency_penalty=config.frequency_penalty,
            presence_penalty=config.presence_penalty,
        )
    
    elif config.provider == APIProvider.ANTHROPIC.value:
        api_key = config.api_key_override or os.environ.get("ANTHROPIC_API_KEY")
        if not api_key:
            raise ValueError("æœªé…ç½® Anthropic API Key")
        
        from langchain_anthropic import ChatAnthropic
        return ChatAnthropic(
            model_name=config.model,
            api_key=api_key,
            max_tokens=config.max_tokens,
            # Anthropic ä¸æ”¯æŒ top_p ç­‰å‚æ•°
        )
    
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ API Provider: {config.provider}")


def build_settings_widgets(config: UserConfig) -> list:
    """æ„å»ºè®¾ç½®é¢æ¿ç»„ä»¶.
    
    Args:
        config: å½“å‰ç”¨æˆ·é…ç½®
        
    Returns:
        Chainlit è¾“å…¥ç»„ä»¶åˆ—è¡¨
    """
    # è·å–å½“å‰ provider çš„æ¨¡å‹åˆ—è¡¨
    models = get_models_for_provider(config.provider)
    model_options = [m["id"] for m in models]
    model_labels = {m["id"]: f"{m['name']} ({m['context']})" for m in models}
    
    # é¢„è®¾é€‰é¡¹
    preset_options = list(CONFIG_PRESETS.keys())
    preset_labels = {k: v["name"] for k, v in CONFIG_PRESETS.items()}
    
    return [
        # === API è®¾ç½® ===
        Select(
            id="provider",
            label="API Provider",
            description="é€‰æ‹© AI æ¨¡å‹æä¾›å•†",
            values=APIProvider.choices(),
            initial_value=config.provider,
        ),
        Select(
            id="model",
            label="æ¨¡å‹",
            description="é€‰æ‹©ä½¿ç”¨çš„æ¨¡å‹",
            values=model_options if model_options else ["deepseek-chat"],
            initial_value=config.model if config.model in model_options else (model_options[0] if model_options else "deepseek-chat"),
        ),
        TextInput(
            id="api_key_override",
            label="API Key (å¯é€‰)",
            description="è¦†ç›–ç¯å¢ƒå˜é‡ä¸­çš„ API Keyï¼Œç•™ç©ºåˆ™ä½¿ç”¨é»˜è®¤é…ç½®",
            initial=config.api_key_override or "",
            placeholder="sk-...",
        ),
        
        # === æ¨¡å‹å‚æ•° ===
        Slider(
            id="temperature",
            label="Temperature",
            description="æ§åˆ¶è¾“å‡ºéšæœºæ€§ (0=ç¡®å®šæ€§, 1=åˆ›æ„æ€§)",
            min=0.0,
            max=1.5,
            step=0.1,
            initial=config.temperature,
        ),
        Slider(
            id="max_tokens",
            label="Max Tokens",
            description="æœ€å¤§è¾“å‡º Token æ•°",
            min=1000,
            max=32000,
            step=1000,
            initial=config.max_tokens,
        ),
        Slider(
            id="top_p",
            label="Top P",
            description="æ ¸é‡‡æ ·å‚æ•°",
            min=0.1,
            max=1.0,
            step=0.05,
            initial=config.top_p,
        ),
        
        # === ç³»ç»Ÿè®¾ç½® ===
        Switch(
            id="enable_mcp",
            label="å¯ç”¨ MCP é›†æˆ",
            description="å¯ç”¨ Model Context Protocol æ‰©å±•åŠŸèƒ½",
            initial=config.enable_mcp,
        ),
        Switch(
            id="auto_approve",
            label="è‡ªåŠ¨å®¡æ‰¹å·¥å…·è°ƒç”¨",
            description="è‡ªåŠ¨æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨ï¼ˆå…³é—­åéœ€æ‰‹åŠ¨å®¡æ‰¹å±é™©æ“ä½œï¼‰",
            initial=config.auto_approve,
        ),
        TextInput(
            id="system_prompt",
            label="ç³»ç»Ÿæç¤ºè¯",
            description="è‡ªå®šä¹‰ Agent ç³»ç»Ÿæç¤ºè¯",
            initial=config.system_prompt,
            placeholder="ä½ æ˜¯æ¸¯è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ...",
        ),
        
        # === é¢„è®¾ ===
        Select(
            id="preset",
            label="é…ç½®é¢„è®¾",
            description="å¿«é€Ÿåº”ç”¨é¢„å®šä¹‰é…ç½®",
            values=preset_options,
            initial_value=config.preset,
        ),
    ]


def settings_to_config(settings: dict, current_config: UserConfig) -> UserConfig:
    """å°†è®¾ç½®é¢æ¿å€¼è½¬æ¢ä¸ºé…ç½®å¯¹è±¡.
    
    Args:
        settings: è®¾ç½®é¢æ¿è¿”å›çš„å­—å…¸
        current_config: å½“å‰é…ç½®ï¼ˆç”¨äºè·å–æœªä¿®æ”¹çš„å€¼ï¼‰
        
    Returns:
        æ›´æ–°åçš„ UserConfig å¯¹è±¡
    """
    # æ£€æŸ¥æ˜¯å¦åˆ‡æ¢äº†é¢„è®¾
    new_preset = settings.get("preset", current_config.preset)
    if new_preset != current_config.preset and new_preset in CONFIG_PRESETS:
        # åº”ç”¨é¢„è®¾
        preset = CONFIG_PRESETS[new_preset]
        return UserConfig(
            provider=settings.get("provider", current_config.provider),
            model=settings.get("model", current_config.model),
            api_key_override=settings.get("api_key_override") or None,
            temperature=preset["temperature"],
            max_tokens=preset["max_tokens"],
            top_p=preset["top_p"],
            frequency_penalty=current_config.frequency_penalty,
            presence_penalty=current_config.presence_penalty,
            system_prompt=settings.get("system_prompt", current_config.system_prompt),
            enable_mcp=settings.get("enable_mcp", current_config.enable_mcp),
            auto_approve=settings.get("auto_approve", current_config.auto_approve),
            preset=new_preset,
        )
    
    # æ­£å¸¸æ›´æ–°
    return UserConfig(
        provider=settings.get("provider", current_config.provider),
        model=settings.get("model", current_config.model),
        api_key_override=settings.get("api_key_override") or None,
        temperature=settings.get("temperature", current_config.temperature),
        max_tokens=int(settings.get("max_tokens", current_config.max_tokens)),
        top_p=settings.get("top_p", current_config.top_p),
        frequency_penalty=current_config.frequency_penalty,
        presence_penalty=current_config.presence_penalty,
        system_prompt=settings.get("system_prompt", current_config.system_prompt),
        enable_mcp=settings.get("enable_mcp", current_config.enable_mcp),
        auto_approve=settings.get("auto_approve", current_config.auto_approve),
        preset=new_preset,
    )


# ============== è®¾ç½®æ›´æ–°å¤„ç† ==============
@cl.on_settings_update
async def on_settings_update(settings: dict):
    """å¤„ç†è®¾ç½®æ›´æ–°.
    
    å½“ç”¨æˆ·åœ¨è®¾ç½®é¢æ¿ä¸­ä¿®æ”¹é…ç½®æ—¶è§¦å‘ã€‚
    """
    user = cl.user_session.get("user")
    user_id = user.identifier if user else "anonymous"
    
    # è·å–å½“å‰é…ç½®
    current_config = cl.user_session.get("config") or get_default_config()
    
    # è½¬æ¢ä¸ºæ–°é…ç½®
    new_config = settings_to_config(settings, current_config)
    
    # éªŒè¯é…ç½®
    errors = new_config.validate()
    if errors:
        await cl.Message(
            content=f"âš ï¸ **é…ç½®éªŒè¯å¤±è´¥**\n\n" + "\n".join(f"- {e}" for e in errors),
            author="system",
        ).send()
        return
    
    # æ£€æŸ¥ provider æ˜¯å¦å˜æ›´ï¼ˆéœ€è¦æ›´æ–°æ¨¡å‹åˆ—è¡¨ï¼‰
    provider_changed = new_config.provider != current_config.provider
    
    # å¦‚æœ provider å˜æ›´ï¼Œé‡ç½®æ¨¡å‹ä¸ºè¯¥ provider çš„ç¬¬ä¸€ä¸ª
    if provider_changed:
        models = get_models_for_provider(new_config.provider)
        if models:
            new_config.model = models[0]["id"]
    
    # ä¿å­˜é…ç½®
    await config_storage.save_config(user_id, new_config)
    cl.user_session.set("config", new_config)
    
    # å¦‚æœ provider å˜æ›´ï¼Œéœ€è¦é‡æ–°åˆå§‹åŒ–è®¾ç½®é¢æ¿
    if provider_changed:
        settings_widgets = build_settings_widgets(new_config)
        await cl.ChatSettings(settings_widgets).send()
    
    # é‡æ–°åˆ›å»º Agent
    try:
        model = create_model_from_config(new_config)
        agent = await create_hkex_agent(
            model=model,
            assistant_id=cl.context.session.id,
            enable_mcp=new_config.enable_mcp,
            system_prompt=new_config.system_prompt,
            use_checkpointer=False,  # Chainlit has its own persistence
            enable_hitl=not new_config.auto_approve,  # è‡ªåŠ¨å®¡æ‰¹ = ç¦ç”¨ HITL
        )
        cl.user_session.set("agent", agent)
        
        # æ˜¾ç¤ºæ›´æ–°æˆåŠŸæ¶ˆæ¯
        provider_name = APIProvider.display_names().get(new_config.provider, new_config.provider)
        await cl.Message(
            content=f"âœ… **é…ç½®å·²æ›´æ–°**\n\n"
                    f"- Provider: {provider_name}\n"
                    f"- æ¨¡å‹: {new_config.get_model_display_name()}\n"
                    f"- Temperature: {new_config.temperature}\n"
                    f"- Max Tokens: {new_config.max_tokens}\n"
                    f"- MCP: {'å¯ç”¨' if new_config.enable_mcp else 'ç¦ç”¨'}\n"
                    f"- è‡ªåŠ¨å®¡æ‰¹: {'å¯ç”¨' if new_config.auto_approve else 'ç¦ç”¨'}",
            author="system",
        ).send()
        
    except Exception as e:
        await cl.Message(
            content=f"âŒ **é…ç½®æ›´æ–°å¤±è´¥**\n\n```\n{str(e)}\n```\n\nè¯·æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®é…ç½®ã€‚",
            author="system",
        ).send()


# ============== å¯¹è¯æ¢å¤ ==============
@cl.on_chat_resume
async def on_chat_resume(thread: dict):
    """æ¢å¤å†å²å¯¹è¯æ—¶çš„å¤„ç†ã€‚"""
    user = cl.user_session.get("user")
    user_id = user.identifier if user else "anonymous"
    
    # åŠ è½½ç”¨æˆ·é…ç½®
    config = await config_storage.load_or_default(user_id)
    cl.user_session.set("config", config)
    
    # â­ ä» thread["steps"] æ¢å¤å†å²æ¶ˆæ¯ï¼ˆå…³é”®ä¿®å¤ï¼ï¼‰
    message_history = []
    for step in thread.get("steps", []):
        step_type = step.get("type")
        step_output = step.get("output", "")
        
        # è·³è¿‡ç©ºæ¶ˆæ¯å’Œç³»ç»Ÿæ¶ˆæ¯
        if not step_output or step_type == "system_message":
            continue
            
        # ç”¨æˆ·æ¶ˆæ¯
        if step_type == "user_message":
            message_history.append(HumanMessage(content=step_output))
        # AI åŠ©æ‰‹æ¶ˆæ¯
        elif step_type == "assistant_message":
            message_history.append(AIMessage(content=step_output))
    
    cl.user_session.set("message_history", message_history)
    
    # åˆ›å»ºæ¨¡å‹å’Œ Agent
    try:
        model = create_model_from_config(config)
        
        agent = await create_hkex_agent(
            model=model,
            assistant_id=thread["id"],
            enable_mcp=config.enable_mcp,
            system_prompt=config.system_prompt,
            use_checkpointer=False,  # Chainlit has its own persistence
            enable_hitl=not config.auto_approve,  # è‡ªåŠ¨å®¡æ‰¹ = ç¦ç”¨ HITL
        )
        
        cl.user_session.set("agent", agent)
        cl.user_session.set("thread_id", thread["id"])
        
        # åˆå§‹åŒ–è®¾ç½®é¢æ¿
        settings_widgets = build_settings_widgets(config)
        await cl.ChatSettings(settings_widgets).send()
        
        await cl.Message(
            content=f"ğŸ“‚ å·²æ¢å¤å¯¹è¯: **{thread.get('name', 'æœªå‘½åå¯¹è¯')}**\n\n"
                    f"âœ… å·²åŠ è½½ **{len(message_history)}** æ¡å†å²æ¶ˆæ¯ï¼Œç»§ç»­æ‚¨çš„åˆ†æ..."
        ).send()
        
    except Exception as e:
        await cl.Message(
            content=f"âŒ **æ¢å¤å¯¹è¯å¤±è´¥**\n\n```\n{str(e)}\n```"
        ).send()


@cl.on_chat_start
async def on_chat_start():
    """åˆå§‹åŒ–èŠå¤©ä¼šè¯ï¼Œåˆ›å»º HKEX Agentã€‚"""
    user = cl.user_session.get("user")
    user_id = user.identifier if user else "anonymous"
    
    # åŠ è½½ç”¨æˆ·é…ç½®
    config = await config_storage.load_or_default(user_id)
    cl.user_session.set("config", config)
    
    # â­ åˆå§‹åŒ–æ¶ˆæ¯å†å²ï¼ˆå…³é”®ï¼šä¿æŒå¯¹è¯ä¸Šä¸‹æ–‡ï¼‰
    cl.user_session.set("message_history", [])
    
    # åˆå§‹åŒ–è®¾ç½®é¢æ¿
    settings_widgets = build_settings_widgets(config)
    await cl.ChatSettings(settings_widgets).send()
    
    # å‘é€æ¬¢è¿æ¶ˆæ¯
    provider_name = APIProvider.display_names().get(config.provider, config.provider)
    await cl.Message(
        content="ğŸ›ï¸ **æ¸¯è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ** å·²å°±ç»ªï¼\n\n"
                "æˆ‘å¯ä»¥å¸®åŠ©æ‚¨ï¼š\n"
                "- ğŸ“° æœç´¢å’Œåˆ†ææ¸¯äº¤æ‰€å…¬å‘Š\n"
                "- ğŸ“„ è§£æ PDF æ–‡æ¡£\n"
                "- ğŸ“Š ç”Ÿæˆåˆ†ææŠ¥å‘Š\n"
                "- ğŸ’¹ æŸ¥è¯¢è‚¡ç¥¨ä¿¡æ¯\n\n"
                f"å½“å‰é…ç½®ï¼š**{provider_name}** / **{config.get_model_display_name()}**\n\n"
                "ğŸ’¡ ç‚¹å‡»å³ä¸Šè§’ âš™ï¸ å›¾æ ‡å¯ä¿®æ”¹æ¨¡å‹å’Œå‚æ•°è®¾ç½®ã€‚"
    ).send()

    # åˆ›å»ºæ¨¡å‹
    try:
        model = create_model_from_config(config)
    except Exception as e:
        await cl.Message(
            content=f"âŒ **æ¨¡å‹åˆå§‹åŒ–å¤±è´¥**\n\nè¯·æ£€æŸ¥ API å¯†é’¥é…ç½®ï¼š\n```\n{str(e)}\n```\n\n"
                    f"ğŸ’¡ æ‚¨å¯ä»¥åœ¨è®¾ç½®é¢æ¿ä¸­è¾“å…¥ API Key æˆ–é…ç½®ç¯å¢ƒå˜é‡ã€‚"
        ).send()
        return

    # åˆ›å»º HKEX Agent
    try:
        agent = await create_hkex_agent(
            model=model,
            assistant_id=cl.context.session.id,
            enable_mcp=config.enable_mcp,
            system_prompt=config.system_prompt,
            use_checkpointer=False,  # Chainlit has its own persistence
            enable_hitl=not config.auto_approve,  # è‡ªåŠ¨å®¡æ‰¹ = ç¦ç”¨ HITL
        )
        # ä¿å­˜åˆ°ç”¨æˆ·ä¼šè¯
        cl.user_session.set("agent", agent)
        cl.user_session.set("thread_id", cl.context.session.id)
        
        if config.enable_mcp:
            await cl.Message(content="ğŸ”Œ MCP é›†æˆå·²å¯ç”¨", author="system").send()
            
    except Exception as e:
        await cl.Message(
            content=f"âŒ **Agent åˆ›å»ºå¤±è´¥**\n\n```\n{str(e)}\n```"
        ).send()


@cl.on_message
async def on_message(message: cl.Message):
    """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨æ­¥éª¤æ˜¾ç¤ºã€‚"""
    agent = cl.user_session.get("agent")
    thread_id = cl.user_session.get("thread_id")

    if not agent:
        await cl.Message(
            content="âš ï¸ Agent æœªåˆå§‹åŒ–ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•ã€‚"
        ).send()
        return

    # è·å–å¹¶æ›´æ–°æ¶ˆæ¯å†å²
    message_history = cl.user_session.get("message_history", [])
    
    # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
    current_message = HumanMessage(content=message.content)
    message_history.append(current_message)

    # é…ç½®
    config = {
        "configurable": {
            "thread_id": thread_id,
        }
    }

    # åˆ›å»ºå“åº”æ¶ˆæ¯
    response_msg = cl.Message(content="")
    await response_msg.send()

    # è·Ÿè¸ªæ´»è·ƒçš„å·¥å…·è°ƒç”¨ Steps
    active_steps: dict[str, cl.Step] = {}

    try:
        # æµå¼å¤„ç† Agent å“åº”
        full_response = ""
        print(f"[DEBUG] Starting astream with {len(message_history)} messages")

        # å•æµæ¨¡å¼ï¼šmessages è·å–æµå¼æ¶ˆæ¯
        event_count = 0
        async for event in agent.astream(
            {"messages": message_history},
            config=config,
            stream_mode="messages",
        ):
            event_count += 1
            msg, metadata = event
            node = metadata.get("langgraph_node", "")
            if event_count <= 5:
                print(f"[DEBUG] Event #{event_count}: node={node}, type={type(msg).__name__}")
            
            # 1. æ£€æµ‹å·¥å…·è°ƒç”¨ - æ”¯æŒ tool_calls å’Œ tool_call_chunks
            # AIMessage ä½¿ç”¨ tool_callsï¼ŒAIMessageChunk ä½¿ç”¨ tool_call_chunks
            tool_calls_list = []
            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                tool_calls_list = msg.tool_calls
            elif hasattr(msg, 'tool_call_chunks') and msg.tool_call_chunks:
                tool_calls_list = msg.tool_call_chunks
            
            if tool_calls_list:
                for tool_call in tool_calls_list:
                    # å…¼å®¹å­—å…¸æ ¼å¼
                    if isinstance(tool_call, dict):
                        tool_name = tool_call.get("name", "") or ""
                        tool_args = tool_call.get("args", {})
                        tool_id = tool_call.get("id", "")
                    else:
                        tool_name = getattr(tool_call, "name", "") or ""
                        tool_args = getattr(tool_call, "args", {})
                        tool_id = getattr(tool_call, "id", "")
                    
                    # è·³è¿‡ç©ºåç§°æˆ–å·²å¤„ç†çš„å·¥å…·
                    if not tool_name or tool_id in active_steps:
                        continue
                    
                    # è®°å½•å·¥å…·è°ƒç”¨ä¿¡æ¯
                    active_steps[tool_id] = {
                        "name": tool_name,
                        "args": tool_args if isinstance(tool_args, dict) else {},
                        "step": None,
                    }
                    print(f"[DEBUG] Registered tool: {tool_name} with id={tool_id}")

            # 2. æ£€æµ‹å·¥å…·æ‰§è¡Œç»“æœ --> åˆ›å»ºå¹¶å®Œæˆ Step
            if hasattr(msg, 'type') and msg.type == "tool":
                tool_id = getattr(msg, 'tool_call_id', None)
                tool_name = getattr(msg, 'name', 'unknown')
                print(f"[DEBUG] Tool result: id={tool_id}, name={tool_name}, content={str(msg.content)[:100]}")
                
                # è·å–å·¥å…·è°ƒç”¨ä¿¡æ¯
                tool_info = active_steps.get(tool_id, {})
                if isinstance(tool_info, dict) and "name" in tool_info:
                    display_name = tool_info.get("name", tool_name)
                    display_args = tool_info.get("args", {})
                else:
                    display_name = tool_name
                    display_args = {}
                
                # åˆ›å»ºå¹¶å®Œæˆ Stepï¼ˆä¸€æ¬¡æ€§æ˜¾ç¤ºè¾“å…¥å’Œè¾“å‡ºï¼‰
                step = cl.Step(name=display_name, type="tool")
                step.input = json.dumps(display_args, ensure_ascii=False, indent=2) if display_args else ""
                
                # æˆªæ–­è¿‡é•¿è¾“å‡º
                content = str(msg.content)
                if len(content) > 2000:
                    step.output = content[:2000] + "\n... [å·²æˆªæ–­]"
                else:
                    step.output = content
                
                await step.send()
                
                # æ£€æµ‹ç”Ÿæˆçš„æ–‡ä»¶å¹¶æä¾›ä¸‹è½½é“¾æ¥
                await check_and_send_file_download(content, display_name)
                
                # æ¸…ç†
                if tool_id in active_steps:
                    del active_steps[tool_id]

            # 3. å¤„ç† AI æœ€ç»ˆå“åº”
            # AIMessageChunk æ˜¯æµå¼æ¶ˆæ¯å—ï¼Œä¹Ÿéœ€è¦å¤„ç†
            if hasattr(msg, 'content') and msg.content:
                msg_type = type(msg).__name__
                if msg_type in ["AIMessage", "AIMessageChunk"] or node in ["agent", "model", "final"]:
                    # æµå¼è¾“å‡º token
                    await response_msg.stream_token(msg.content)
                    full_response += msg.content

        # æ›´æ–°æœ€ç»ˆæ¶ˆæ¯
        if full_response:
            response_msg.content = full_response
            await response_msg.update()
            # å°† AI å“åº”ä¹Ÿæ·»åŠ åˆ°å†å²
            message_history.append(AIMessage(content=full_response))
        else:
            response_msg.content = "âœ… ä»»åŠ¡å·²å®Œæˆ"
            await response_msg.update()
        
        # ä¿å­˜æ›´æ–°åçš„æ¶ˆæ¯å†å²
        cl.user_session.set("message_history", message_history)

    except Exception as e:
        import traceback
        print(f"[ERROR] Exception in on_message: {e}")
        print(f"[ERROR] Traceback: {traceback.format_exc()}")
        
        # å¼‚å¸¸æ—¶å…³é—­æ‰€æœ‰æœªå®Œæˆçš„ Steps
        for tool_info in active_steps.values():
            if isinstance(tool_info, dict) and tool_info.get("step"):
                step = tool_info["step"]
                step.output = f"âŒ é”™è¯¯: {str(e)}"
                await step.update()
        
        error_msg = f"âŒ **å¤„ç†å‡ºé”™**\n\n```\n{str(e)}\n```"
        response_msg.content = error_msg
        await response_msg.update()


@cl.on_stop
async def on_stop():
    """å¤„ç†ç”¨æˆ·åœæ­¢è¯·æ±‚ã€‚"""
    await cl.Message(content="â¹ï¸ å·²åœæ­¢å½“å‰ä»»åŠ¡").send()


# å¤„ç†äººæœºäº¤äº’å®¡æ‰¹
@cl.action_callback("approve")
async def on_action_approve(action: cl.Action):
    """å¤„ç†å·¥å…·å®¡æ‰¹ã€‚"""
    await cl.Message(content="âœ… å·²æ‰¹å‡†æ‰§è¡Œ").send()
    return "approve"


@cl.action_callback("reject")
async def on_action_reject(action: cl.Action):
    """å¤„ç†å·¥å…·æ‹’ç»ã€‚"""
    await cl.Message(content="âŒ å·²æ‹’ç»æ‰§è¡Œ").send()
    return "reject"
