# API é€Ÿç‡é™åˆ¶å¤„ç†æ–¹æ¡ˆ

## é—®é¢˜æè¿°

å½“é‡åˆ°ä»¥ä¸‹é”™è¯¯æ—¶ï¼š

```
âŒ Error: Error code: 429 - {'message': 'Request was rejected due to rate limiting. Details: TPM limit reached.'}
```

è¿™è¡¨ç¤º API è°ƒç”¨è¶…è¿‡äº†æœåŠ¡æä¾›å•†çš„é€Ÿç‡é™åˆ¶ï¼ˆTPM = Tokens Per Minuteï¼Œæ¯åˆ†é’Ÿä»¤ç‰Œæ•°ï¼‰ã€‚

## è§£å†³æ–¹æ¡ˆæ¦‚è¿°

é¡¹ç›®å·²é›†æˆ**è‡ªåŠ¨é‡è¯•æœºåˆ¶ + é€Ÿç‡é™åˆ¶å™¨**ï¼Œæ— éœ€æ‰‹åŠ¨å¹²é¢„å³å¯å¤„ç† 429 é”™è¯¯ã€‚

### æ ¸å¿ƒåŠŸèƒ½

1. **æŒ‡æ•°é€€é¿é‡è¯•** - è‡ªåŠ¨é‡è¯•å¤±è´¥çš„è¯·æ±‚ï¼Œå»¶è¿Ÿæ—¶é—´æŒ‡æ•°å¢é•¿
2. **ä»¤ç‰Œæ¡¶é€Ÿç‡é™åˆ¶** - ä¸»åŠ¨æ§åˆ¶è¯·æ±‚é¢‘ç‡ï¼Œé¢„é˜²è¶…é™
3. **æ™ºèƒ½é”™è¯¯è¯†åˆ«** - è‡ªåŠ¨è¯†åˆ«å¯é‡è¯•çš„é”™è¯¯ï¼ˆ429, 5xxï¼‰
4. **å¹¶å‘æ§åˆ¶** - é™åˆ¶åŒæ—¶è¿›è¡Œçš„è¯·æ±‚æ•°é‡

## æ¶æ„å®ç°

### 1. é€Ÿç‡é™åˆ¶å™¨ (`rate_limiter.py`)

```python
# ä»¤ç‰Œæ¡¶ç®—æ³• - æ§åˆ¶è¯·æ±‚é¢‘ç‡
class TokenBucketRateLimiter:
    - tokens_per_minute: æ¯åˆ†é’Ÿå…è®¸çš„ä»¤ç‰Œæ•°
    - burst_size: å…è®¸çš„çªå‘è¯·æ±‚é‡
    - acquire(tokens): è·å–ä»¤ç‰Œï¼ˆä¸è¶³æ—¶ç­‰å¾…ï¼‰
```

### 2. æŒ‡æ•°é€€é¿é‡è¯• (`rate_limiter.py`)

```python
# é‡è¯•ç­–ç•¥
@async_retry_with_backoff(
    max_retries=5,        # æœ€å¤šé‡è¯• 5 æ¬¡
    base_delay=1.0,       # åŸºç¡€å»¶è¿Ÿ 1 ç§’
    max_delay=60.0,       # æœ€å¤§å»¶è¿Ÿ 60 ç§’
    exponential_base=2.0, # æŒ‡æ•°åŸºæ•° 2
    jitter=True           # æ·»åŠ éšæœºæŠ–åŠ¨
)
```

**å»¶è¿Ÿè®¡ç®—å…¬å¼**ï¼š
```
delay = min(max_delay, base_delay * (exponential_base ^ retry_count))
```

ç¤ºä¾‹å»¶è¿Ÿåºåˆ—ï¼š1s â†’ 2s â†’ 4s â†’ 8s â†’ 16s

### 3. å¼¹æ€§æ¨¡å‹åŒ…è£…å™¨ (`resilient_model.py`)

```python
# ä¸º LangChain æ¨¡å‹æ·»åŠ å¼¹æ€§åŠŸèƒ½
ResilientChatModel:
    - è‡ªåŠ¨å¤„ç† 429 é”™è¯¯
    - è‡ªåŠ¨å¤„ç† 5xx æœåŠ¡å™¨é”™è¯¯
    - é€æ˜ä»£ç†åº•å±‚æ¨¡å‹çš„æ‰€æœ‰åŠŸèƒ½
```

### 4. é…ç½®é›†æˆ (`config.py`)

```python
def create_model(enable_resilience=True):
    # åˆ›å»ºåŸºç¡€æ¨¡å‹
    base_model = ChatOpenAI(...)
    
    # åŒ…è£…ä¸ºå¼¹æ€§æ¨¡å‹ï¼ˆé»˜è®¤å¯ç”¨ï¼‰
    return wrap_model_with_resilience(base_model, ...)
```

## ç¯å¢ƒå˜é‡é…ç½®

### é€Ÿç‡é™åˆ¶é…ç½®

```bash
# .env æ–‡ä»¶æˆ–ç¯å¢ƒå˜é‡

# æ˜¯å¦å¯ç”¨å¼¹æ€§åŠŸèƒ½ï¼ˆé»˜è®¤: trueï¼‰
ENABLE_MODEL_RESILIENCE=true

# æ¯åˆ†é’Ÿä»¤ç‰Œé™åˆ¶ï¼ˆé»˜è®¤: 50000ï¼‰
API_TOKENS_PER_MINUTE=50000

# çªå‘è¯·æ±‚ä»¤ç‰Œæ•°ï¼ˆé»˜è®¤: 10000ï¼‰
API_BURST_SIZE=10000

# æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ˆé»˜è®¤: 5ï¼‰
API_MAX_RETRIES=5

# åŸºç¡€å»¶è¿Ÿæ—¶é—´/ç§’ï¼ˆé»˜è®¤: 1.0ï¼‰
API_BASE_DELAY=1.0

# æœ€å¤§å»¶è¿Ÿæ—¶é—´/ç§’ï¼ˆé»˜è®¤: 60.0ï¼‰
API_MAX_DELAY=60.0

# æœ€å¤§å¹¶å‘è¯·æ±‚æ•°ï¼ˆé»˜è®¤: 5ï¼‰
API_MAX_CONCURRENT=5
```

### æ ¹æ®ä¸åŒ API æä¾›å•†è°ƒæ•´

#### SiliconFlow (DeepSeek)

```bash
# å…è´¹å¥—é¤ç¤ºä¾‹é…ç½®
API_TOKENS_PER_MINUTE=20000
API_BURST_SIZE=5000
API_MAX_CONCURRENT=3
```

#### OpenAI

```bash
# GPT-4 æ ‡å‡†å¥—é¤
API_TOKENS_PER_MINUTE=90000
API_BURST_SIZE=15000
API_MAX_CONCURRENT=10
```

#### Anthropic (Claude)

```bash
# Claude æ ‡å‡†å¥—é¤
API_TOKENS_PER_MINUTE=40000
API_BURST_SIZE=8000
API_MAX_CONCURRENT=5
```

## ä½¿ç”¨ç¤ºä¾‹

### è‡ªåŠ¨æ¨¡å¼ï¼ˆæ¨èï¼‰

ç³»ç»Ÿå·²é»˜è®¤å¯ç”¨ï¼Œæ— éœ€é¢å¤–é…ç½®ï¼š

```bash
# ç›´æ¥ä½¿ç”¨ï¼Œé‡åˆ° 429 é”™è¯¯ä¼šè‡ªåŠ¨é‡è¯•
python -m src.cli.main
```

**ç»ˆç«¯è¾“å‡ºç¤ºä¾‹**ï¼š

```
Using SiliconFlow model: deepseek-chat
  temperature=0.1, max_tokens=8192
  ğŸ›¡ï¸  å¼¹æ€§åŠŸèƒ½å·²å¯ç”¨: max_retries=5, TPM=50000

âš ï¸  é€Ÿç‡é™åˆ¶: Error code: 429 - TPM limit reached
ğŸ”„ ç¬¬ 1/5 æ¬¡é‡è¯•ï¼Œç­‰å¾… 1.2ç§’...
âœ… é‡è¯•æˆåŠŸ
```

### æ‰‹åŠ¨é…ç½®æ¨¡å¼

å¦‚æœéœ€è¦è‡ªå®šä¹‰é…ç½®ï¼š

```python
from src.cli.config import create_model
from src.cli.rate_limiter import TokenBucketRateLimiter
from src.cli.resilient_model import wrap_model_with_resilience

# åˆ›å»ºåŸºç¡€æ¨¡å‹
base_model = create_model(enable_resilience=False)

# è‡ªå®šä¹‰é€Ÿç‡é™åˆ¶å™¨
custom_limiter = TokenBucketRateLimiter(
    tokens_per_minute=30000,  # è‡ªå®šä¹‰é™åˆ¶
    burst_size=6000
)

# åº”ç”¨å¼¹æ€§åŠŸèƒ½
resilient_model = wrap_model_with_resilience(
    model=base_model,
    max_retries=3,
    base_delay=2.0,
    rate_limiter=custom_limiter
)
```

### ç¦ç”¨å¼¹æ€§åŠŸèƒ½

```bash
# å¦‚æœéœ€è¦ç¦ç”¨ï¼ˆä¸æ¨èï¼‰
export ENABLE_MODEL_RESILIENCE=false
```

æˆ–åœ¨ä»£ç ä¸­ï¼š

```python
model = create_model(enable_resilience=False)
```

## ç›‘æ§å’Œè°ƒè¯•

### æŸ¥çœ‹é€Ÿç‡é™åˆ¶çŠ¶æ€

ç³»ç»Ÿä¼šåœ¨ç»ˆç«¯è¾“å‡ºå®æ—¶çŠ¶æ€ï¼š

```
â³ é€Ÿç‡é™åˆ¶: ç­‰å¾… 3.5ç§’ (éœ€è¦ 2500 ä¸ªä»¤ç‰Œ)
```

### æŸ¥çœ‹é‡è¯•è¿‡ç¨‹

```
âš ï¸  é€Ÿç‡é™åˆ¶: Error code: 429 - ...
ğŸ”„ ç¬¬ 2/5 æ¬¡é‡è¯•ï¼Œç­‰å¾… 2.1ç§’...
```

### è°ƒè¯•æ¨¡å¼

å¢åŠ ç¯å¢ƒå˜é‡è¾“å‡ºï¼š

```bash
export PYTHONUNBUFFERED=1
export API_MAX_RETRIES=10  # å¢åŠ é‡è¯•æ¬¡æ•°ä»¥ä¾¿è§‚å¯Ÿ
```

## æœ€ä½³å®è·µ

### 1. æ ¹æ®å¥—é¤é…ç½®é™åˆ¶

æŸ¥çœ‹ä½ çš„ API å¥—é¤é™åˆ¶ï¼š

- **SiliconFlow**: [ä»·æ ¼é¡µé¢](https://siliconflow.cn/pricing)
- **OpenAI**: [Rate Limits](https://platform.openai.com/docs/guides/rate-limits)
- **Anthropic**: [Rate Limits](https://docs.anthropic.com/claude/reference/rate-limits)

è®¾ç½® `API_TOKENS_PER_MINUTE` ä¸ºå®é™…é™åˆ¶çš„ **80%**ï¼Œç•™å‡ºå®‰å…¨ä½™é‡ã€‚

### 2. ä¼˜åŒ–è¯·æ±‚ç­–ç•¥

```python
# âŒ é¿å…çŸ­æ—¶é—´å†…å¤§é‡è¯·æ±‚
for item in large_list:
    response = agent.analyze(item)  # å¯èƒ½è§¦å‘é€Ÿç‡é™åˆ¶

# âœ… ä½¿ç”¨æ‰¹å¤„ç†æˆ–å¢åŠ é—´éš”
import asyncio

async def process_batch(items):
    tasks = [agent.analyze_async(item) for item in items]
    return await asyncio.gather(*tasks)  # è‡ªåŠ¨é€Ÿç‡æ§åˆ¶
```

### 3. ç›‘æ§ Token ä½¿ç”¨

```python
from src.cli.token_utils import TokenTracker

tracker = TokenTracker(model_name="deepseek-chat")
# ä½¿ç”¨åæŸ¥çœ‹ç»Ÿè®¡
print(f"Total tokens: {tracker.total_tokens}")
print(f"Cost: ${tracker.total_cost:.4f}")
```

### 4. åº”å¯¹çªå‘æµé‡

```bash
# ä¸´æ—¶å¢åŠ çªå‘å®¹é‡
export API_BURST_SIZE=15000

# æˆ–å‡å°‘å¹¶å‘
export API_MAX_CONCURRENT=2
```

## é”™è¯¯å¤„ç†çŸ©é˜µ

| é”™è¯¯ç±»å‹ | çŠ¶æ€ç  | è‡ªåŠ¨é‡è¯• | å»ºè®®æ“ä½œ |
|---------|--------|---------|---------|
| é€Ÿç‡é™åˆ¶ | 429 | âœ… æ˜¯ | é™ä½ `API_TOKENS_PER_MINUTE` |
| æœåŠ¡å™¨é”™è¯¯ | 500-504 | âœ… æ˜¯ | ç­‰å¾…æœåŠ¡æ¢å¤ |
| è¶…æ—¶ | Timeout | âœ… æ˜¯ | å¢åŠ  `API_MAX_DELAY` |
| é…é¢è€—å°½ | 429 | âœ… æ˜¯ | å‡çº§å¥—é¤æˆ–ç­‰å¾…é‡ç½® |
| è®¤è¯é”™è¯¯ | 401 | âŒ å¦ | æ£€æŸ¥ API Key |
| å‚æ•°é”™è¯¯ | 400 | âŒ å¦ | ä¿®æ­£è¯·æ±‚å‚æ•° |

## æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: ä»ç„¶é‡åˆ° 429 é”™è¯¯

**åŸå› **: é€Ÿç‡é™åˆ¶è®¾ç½®è¿‡é«˜

**è§£å†³**:

```bash
# é™ä½é™åˆ¶åˆ°å®é™…é…é¢çš„ 50%
export API_TOKENS_PER_MINUTE=25000
export API_BURST_SIZE=5000
```

### é—®é¢˜ 2: è¯·æ±‚å¤ªæ…¢

**åŸå› **: é€Ÿç‡é™åˆ¶è¿‡äºä¿å®ˆ

**è§£å†³**:

```bash
# å¢åŠ é™åˆ¶ï¼ˆç¡®ä¿ä¸è¶…è¿‡å®é™…é…é¢ï¼‰
export API_TOKENS_PER_MINUTE=80000
export API_MAX_CONCURRENT=10
```

### é—®é¢˜ 3: é‡è¯•æ¬¡æ•°è€—å°½

**åŸå› **: åŸºç¡€å»¶è¿Ÿæˆ–æœ€å¤§å»¶è¿Ÿè®¾ç½®ä¸å½“

**è§£å†³**:

```bash
# å¢åŠ æœ€å¤§é‡è¯•æ¬¡æ•°å’Œå»¶è¿Ÿ
export API_MAX_RETRIES=10
export API_MAX_DELAY=120
```

### é—®é¢˜ 4: å¯¼å…¥é”™è¯¯

**åŸå› **: æ¨¡å—æœªæ­£ç¡®å®‰è£…

**è§£å†³**:

```bash
# é‡æ–°å®‰è£…ä¾èµ–
pip install -e .
# æˆ–
uv pip install -e .
```

## å‡çº§å»ºè®®

### å¦‚æœé¢‘ç¹é‡åˆ°é€Ÿç‡é™åˆ¶

1. **å‡çº§ API å¥—é¤**
   - å¢åŠ  TPM é…é¢
   - å‡å°‘ç­‰å¾…æ—¶é—´

2. **ä¼˜åŒ– Token ä½¿ç”¨**
   - ç®€åŒ– Prompt
   - ä½¿ç”¨æ›´å°çš„æ¨¡å‹
   - å¯ç”¨å“åº”ç¼“å­˜

3. **ä½¿ç”¨å¤šä¸ª API Key**
   ```python
   # å®ç°ç®€å•çš„è´Ÿè½½å‡è¡¡
   keys = [key1, key2, key3]
   current_key = keys[request_count % len(keys)]
   ```

## æŠ€æœ¯ç»†èŠ‚

### ä»¤ç‰Œä¼°ç®—ç®—æ³•

```python
# ç®€åŒ–ä¼°ç®—ï¼š1 token â‰ˆ 4 å­—ç¬¦ï¼ˆè‹±æ–‡ï¼‰
estimated_tokens = len(text) // 4

# ä¿å®ˆä¼°ç®—
estimated_tokens = max(estimated_tokens, 500)  # æœ€å° 500
```

### é‡è¯•åˆ¤æ–­é€»è¾‘

```python
def is_retryable_error(error: Exception) -> bool:
    error_str = str(error).lower()
    return any([
        "429" in error_str,
        "rate limit" in error_str,
        "tpm limit" in error_str,
        "quota" in error_str,
        "500" in error_str,
        "502" in error_str,
        "503" in error_str,
        "timeout" in error_str,
    ])
```

## å‚è€ƒèµ„æ–™

- [LangChain é”™è¯¯å¤„ç†](https://python.langchain.com/docs/guides/safety/error_handling)
- [ä»¤ç‰Œæ¡¶ç®—æ³•](https://en.wikipedia.org/wiki/Token_bucket)
- [æŒ‡æ•°é€€é¿ç­–ç•¥](https://en.wikipedia.org/wiki/Exponential_backoff)
- [OpenAI Rate Limits Best Practices](https://platform.openai.com/docs/guides/rate-limits/rate-limits-best-practices)

## æ›´æ–°æ—¥å¿—

- **2025-11-09**: åˆå§‹ç‰ˆæœ¬ - æ·»åŠ å®Œæ•´é€Ÿç‡é™åˆ¶å’Œé‡è¯•æœºåˆ¶
  - å®ç° `TokenBucketRateLimiter`
  - å®ç° `ExponentialBackoff`
  - å®ç° `ResilientChatModel`
  - é›†æˆåˆ° `create_model()`

---

**ç»´æŠ¤è€…**: DeepAgents-HK Team  
**æœ€åæ›´æ–°**: 2025-11-09

