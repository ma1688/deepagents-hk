"""Configuration, constants, and model creation for the CLI."""

import os
import sys
from pathlib import Path
from typing import Union

import dotenv
from rich.console import Console
from rich.text import Text

dotenv.load_dotenv()

# Color scheme
COLORS = {
    "primary": "#10b981",
    "dim": "#6b7280",
    "user": "#ffffff",
    "agent": "#10b981",
    "thinking": "#34d399",
    "tool": "#fbbf24",
}

# å½©è™¹æ¸å˜è‰² - ç”¨äºŽASCIIæ¨ªå¹…
RAINBOW_COLORS = [
    "#ff0000",  # çº¢
    "#ff7f00",  # æ©™
    "#ffff00",  # é»„
    "#00ff00",  # ç»¿
    "#00ffff",  # é’
    "#0000ff",  # è“
    "#8b00ff",  # ç´«
]

def get_hkex_banner(font: str = "slant", rainbow: bool = True) -> Union[Text, str]:
    """åŠ¨æ€ç”ŸæˆHKEX Agentæ¨ªå¹…ï¼Œæ”¯æŒå½©è™¹æ¸å˜æ•ˆæžœ.
    
    Args:
        font: å­—ä½“é£Žæ ¼ (slant, standard, banner, digitalç­‰)
            å¯é€šè¿‡çŽ¯å¢ƒå˜é‡ HKEX_ASCII_FONT é…ç½®
        rainbow: æ˜¯å¦å¯ç”¨å½©è™¹æ¸å˜æ•ˆæžœ
            å¯é€šè¿‡çŽ¯å¢ƒå˜é‡ HKEX_RAINBOW=true/false é…ç½®
    
    Returns:
        Rich Textå¯¹è±¡(å½©è™¹æ¨¡å¼) æˆ– å­—ç¬¦ä¸²(æ™®é€šæ¨¡å¼)
    """
    # ä»ŽçŽ¯å¢ƒå˜é‡è¯»å–é…ç½®
    font = os.getenv("HKEX_ASCII_FONT", font)
    rainbow = os.getenv("HKEX_RAINBOW", str(rainbow)).lower() in ("true", "1", "yes")
    
    try:
        import pyfiglet
        # ç”ŸæˆASCIIè‰ºæœ¯å­—
        banner_text = pyfiglet.figlet_format("HKEX Agent", font=font)
        
        if rainbow:
            # åˆ›å»ºå½©è™¹æ¸å˜æ•ˆæžœ
            text = Text()
            lines = banner_text.split("\n")
            
            for i, line in enumerate(lines):
                # ä¸ºæ¯è¡Œåˆ†é…é¢œè‰²ï¼ˆæ¸å˜æ•ˆæžœï¼‰
                color_idx = i % len(RAINBOW_COLORS)
                text.append(line + "\n", style=f"bold {RAINBOW_COLORS[color_idx]}")
            
            return text
        else:
            return banner_text
            
    except ImportError:
        # å¦‚æžœpyfigletæœªå®‰è£…ï¼Œè¿”å›žç®€å•ç‰ˆæœ¬
        return "ðŸ¢ HKEX Agent | æ¸¯äº¤æ‰€å…¬å‘Šåˆ†æžåŠ©æ‰‹\n"
    except Exception:
        # å¦‚æžœå­—ä½“ä¸å­˜åœ¨æˆ–å…¶ä»–é”™è¯¯ï¼Œè¿”å›žé»˜è®¤
        return "ðŸ¢ HKEX Agent | æ¸¯äº¤æ‰€å…¬å‘Šåˆ†æžåŠ©æ‰‹\n"


# ASCII art banner - åŠ¨æ€ç”Ÿæˆ
HKEX_AGENT_ASCII = get_hkex_banner()

# Interactive commands
COMMANDS = {
    "clear": "Clear screen and reset conversation",
    "help": "Show help information",
    "skills": "Manage and view available skills (list/show/search)",
    "memory": "View memory configuration paths",
    "tokens": "Show token usage for current session",
    "quit": "Exit the CLI",
    "exit": "Exit the CLI",
}

# Maximum argument length for display
MAX_ARG_LENGTH = 150

# Agent configuration
config = {"recursion_limit": 1000}

# Rich console instance
console = Console(highlight=False)


class SessionState:
    """Holds mutable session state (auto-approve mode, etc)."""

    def __init__(self, auto_approve: bool = False, show_thinking: bool = False):
        self.auto_approve = auto_approve
        self.show_thinking = show_thinking
        self.show_tool_outputs = False
        self.exit_hint_until: float | None = None
        self.exit_hint_handle = None

    def toggle_auto_approve(self) -> bool:
        """Toggle auto-approve and return new state."""
        self.auto_approve = not self.auto_approve
        return self.auto_approve
    
    def toggle_tool_outputs(self) -> bool:
        """Toggle tool output visibility and return new state."""
        self.show_tool_outputs = not self.show_tool_outputs
        return self.show_tool_outputs


def create_model():
    """Create the appropriate model based on available API keys.
    
    Uses unified configuration from agent_model_config for temperature and max_tokens.

    Priority: SiliconFlow > OpenAI > Anthropic

    Returns:
        ChatModel instance (SiliconFlow, OpenAI, or Anthropic)

    Raises:
        SystemExit if no API key is configured
    """
    # Import unified config
    from src.config.agent_config import agent_model_config
    
    # Check SiliconFlow first (highest priority)
    siliconflow_key = os.environ.get("SILICONFLOW_API_KEY")
    if siliconflow_key:
        from langchain_openai import ChatOpenAI

        model_name = os.environ.get("SILICONFLOW_MODEL", "deepseek-chat")
        console.print(f"[dim]Using SiliconFlow model: {model_name}[/dim]", justify="center")
        console.print(f"[dim]  temperature={agent_model_config.temperature}, max_tokens={agent_model_config.max_tokens}[/dim]", justify="center")
        return ChatOpenAI(
            model=model_name,
            base_url="https://api.siliconflow.cn/v1",
            api_key=siliconflow_key,
            temperature=agent_model_config.temperature,
            max_tokens=agent_model_config.max_tokens,
        )

    # Check OpenAI
    openai_key = os.environ.get("OPENAI_API_KEY")
    if openai_key:
        from langchain_openai import ChatOpenAI

        model_name = os.environ.get("OPENAI_MODEL", "gpt-5-mini")
        console.print(f"[dim]Using OpenAI model: {model_name}[/dim]", justify="center")
        console.print(f"[dim]  temperature={agent_model_config.temperature}, max_tokens={agent_model_config.max_tokens}[/dim]", justify="center")
        return ChatOpenAI(
            model=model_name,
            temperature=agent_model_config.temperature,
            max_tokens=agent_model_config.max_tokens,
        )

    # Check Anthropic
    anthropic_key = os.environ.get("ANTHROPIC_API_KEY")
    if anthropic_key:
        from langchain_anthropic import ChatAnthropic

        model_name = os.environ.get(
            "ANTHROPIC_MODEL", "claude-sonnet-4-5-20250929"
        )
        console.print(f"[dim]Using Anthropic model: {model_name}[/dim]", justify="center")
        console.print(f"[dim]  max_tokens={agent_model_config.max_tokens}[/dim]", justify="center")
        return ChatAnthropic(
            model_name=model_name,
            max_tokens=agent_model_config.max_tokens,
        )

    # No API key found
    console.print("[bold red]Error:[/bold red] No API key configured.")
    console.print("\nPlease set one of the following environment variables:")
    console.print("  - SILICONFLOW_API_KEY  (for SiliconFlow models like deepseek-chat)")
    console.print("  - OPENAI_API_KEY       (for OpenAI models like gpt-5-mini)")
    console.print("  - ANTHROPIC_API_KEY    (for Claude models)")
    console.print("\nExample:")
    console.print("  export SILICONFLOW_API_KEY=your_api_key_here")
    console.print("  export SILICONFLOW_MODEL=deepseek-chat  # optional")
    console.print("\nOr add it to your .env file.")
    sys.exit(1)

