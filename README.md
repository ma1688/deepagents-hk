# ğŸ§ ğŸ¤– Deep Agents - HKEX æ¸¯è‚¡æ™ºèƒ½åˆ†æç³»ç»Ÿ

æœ¬é¡¹ç›®æ˜¯åŸºäº Deep Agents æ¡†æ¶å¼€å‘çš„æ¸¯è‚¡äº¤æ˜“æ•°æ®åˆ†ææ™ºèƒ½ä»£ç†ç³»ç»Ÿï¼Œä¸“é—¨ç”¨äºå¤„ç†æ¸¯äº¤æ‰€å…¬å‘Šã€PDF æ–‡æ¡£è§£æå’Œæ™ºèƒ½æ‘˜è¦ç”Ÿæˆã€‚

## é¡¹ç›®æ¦‚è¿°

Deep Agents é‡‡ç”¨ LLM å¾ªç¯è°ƒç”¨å·¥å…·çš„æ¶æ„ï¼Œé€šè¿‡å®ç°**è§„åˆ’å·¥å…·**ã€**å­ä»£ç†**ã€**æ–‡ä»¶ç³»ç»Ÿ**å’Œ**è¯¦ç»†æç¤ºè¯**å››å¤§æ ¸å¿ƒç»„ä»¶ï¼Œè§£å†³äº†ä¼ ç»Ÿä»£ç†åœ¨å¤æ‚ä»»åŠ¡ä¸­"æµ…å±‚å¤„ç†"çš„é—®é¢˜ã€‚

æœ¬é¡¹ç›®ä¸“é—¨é’ˆå¯¹æ¸¯è‚¡å¸‚åœºæ•°æ®åˆ†æè¿›è¡Œäº†ä¼˜åŒ–ï¼Œä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
- ğŸ“„ **PDF å…¬å‘Šè§£æ**ï¼šæ™ºèƒ½è§£ææ¸¯äº¤æ‰€ PDF å…¬å‘Šæ–‡ä»¶ï¼ˆæ”¯æŒå¤§å‹å¹´æŠ¥è‡ªåŠ¨æˆªæ–­ï¼‰
- ğŸ” **å†…å®¹æ‘˜è¦ç”Ÿæˆ**ï¼šè‡ªåŠ¨ç”Ÿæˆå…³é”®ä¿¡æ¯æ‘˜è¦
- ğŸ“Š **ç»“æ„åŒ–æ•°æ®æå–**ï¼šä»éç»“æ„åŒ–æ–‡æ¡£ä¸­æå–ç»“æ„åŒ–æ•°æ®
- ğŸ’¾ **ç¼“å­˜ç®¡ç†**ï¼šæ™ºèƒ½ç¼“å­˜å·²å¤„ç†çš„æ–‡æ¡£å’Œæ‘˜è¦
- âš¡ **æ™ºèƒ½æˆªæ–­**ï¼šå¤§å‹ PDFï¼ˆ> 50k å­—ç¬¦ï¼‰è‡ªåŠ¨ä¿å­˜åˆ°ç¼“å­˜ï¼Œé˜²æ­¢ LLM token æº¢å‡º

<img src="deep_agents.png" alt="deep agent" width="600"/>

**æŠ€æœ¯è‡´è°¢ï¼šæœ¬é¡¹ç›®ä¸»è¦çµæ„Ÿæ¥æºäº Claude Codeï¼Œæ—¨åœ¨æ¢ç´¢å…¶é€šç”¨åŒ–èƒ½åŠ›å¹¶è¿›è¡Œä¸“é—¨åŒ–å®šåˆ¶ã€‚**

## å®‰è£…

```bash
# ä½¿ç”¨ uv (æ¨è)
uv sync

# æˆ–ä½¿ç”¨ pip
pip install -r requirements.txt

# æˆ–ä½¿ç”¨ poetry
poetry install
```

## ç¯å¢ƒé…ç½®

åˆ›å»º `.env` æ–‡ä»¶å¹¶é…ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡ï¼š

```bash
# ========== LLM Provider API Keys ==========
# ä¼˜å…ˆçº§: SiliconFlow > OpenAI > Anthropic

# SiliconFlow (æ¨è - æˆæœ¬ä¼˜åŒ–)
SILICONFLOW_API_KEY=your_siliconflow_api_key
SILICONFLOW_MODEL=deepseek-ai/DeepSeek-V3.1-Terminus  # ä¸»Agentæ¨¡å‹
SILICONFLOW_PDF_MODEL=Qwen/Qwen2.5-7B-Instruct       # PDFåˆ†æå­Agent
SILICONFLOW_REPORT_MODEL=Qwen/Qwen2.5-72B-Instruct   # æŠ¥å‘Šç”Ÿæˆå­Agent

# OpenAI
OPENAI_API_KEY=your_openai_api_key
OPENAI_MODEL=gpt-4o  # å¯é€‰ï¼Œé»˜è®¤gpt-5-mini

# Anthropic (Claude)
ANTHROPIC_API_KEY=your_anthropic_api_key
ANTHROPIC_MODEL=claude-sonnet-4-5-20250929  # å¯é€‰

# ========== æ¨¡å‹å‚æ•° ==========
SILICONFLOW_TEMPERATURE=0.7           # æ¸©åº¦ (0.0-1.0)
SILICONFLOW_MAX_TOKENS=20000          # æœ€å¤§tokenæ•°
SILICONFLOW_TOP_P=0.9                 # Top-pé‡‡æ · (å¯é€‰)
SILICONFLOW_FREQUENCY_PENALTY=0.0     # é¢‘ç‡æƒ©ç½š (å¯é€‰)
SILICONFLOW_PRESENCE_PENALTY=0.0      # å­˜åœ¨æƒ©ç½š (å¯é€‰)
SILICONFLOW_API_TIMEOUT=60            # APIè¶…æ—¶(ç§’)
SILICONFLOW_API_RETRY=3               # é‡è¯•æ¬¡æ•°

# å­Agentç‹¬ç«‹æ¸©åº¦é…ç½® (å¯é€‰)
SILICONFLOW_PDF_TEMPERATURE=0.5       # PDFåˆ†ææ¸©åº¦
SILICONFLOW_REPORT_TEMPERATURE=0.7    # æŠ¥å‘Šç”Ÿæˆæ¸©åº¦

# ========== UIé…ç½® ==========
HKEX_ASCII_FONT=slant                 # ASCIIæ¨ªå¹…å­—ä½“ (571ç§å¯é€‰)
HKEX_RAINBOW=true                     # å½©è™¹æ¸å˜æ•ˆæœ (true/false)

# ========== å…¶ä»–åŠŸèƒ½ ==========
TAVILY_API_KEY=your_tavily_api_key    # ç½‘ç»œæœç´¢åŠŸèƒ½
```

è¯¦ç»†é…ç½®è¯´æ˜è¯·å‚è€ƒ `.env.example` æ–‡ä»¶ã€‚

## å¿«é€Ÿå¼€å§‹

### æ¸¯è‚¡å…¬å‘Šåˆ†æç¤ºä¾‹

```python
import os
from hkex_agent import HKEXAnalyzer

# åˆå§‹åŒ–åˆ†æå™¨
analyzer = HKEXAnalyzer()

# åˆ†æ PDF å…¬å‘Š
result = analyzer.analyze_announcement("path/to/hkex_announcement.pdf")

print("æ‘˜è¦:", result.summary)
print("å…³é”®æ•°æ®:", result.key_data)
print("å¸‚åœºå½±å“:", result.market_impact)
```

### åŸºç¡€ Deep Agents ä½¿ç”¨

(è¿è¡Œä»¥ä¸‹ç¤ºä¾‹éœ€è¦ `pip install tavily-python`)

ç¡®ä¿åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½®äº† `TAVILY_API_KEY`ã€‚ä½ å¯ä»¥ [åœ¨è¿™é‡Œ](https://www.tavily.com/) ç”Ÿæˆä¸€ä¸ªã€‚

```python
import os
from typing import Literal
from tavily import TavilyClient
from deepagents import create_deep_agent

tavily_client = TavilyClient(api_key=os.environ["TAVILY_API_KEY"])

# Web search tool
def internet_search(
    query: str,
    max_results: int = 5,
    topic: Literal["general", "news", "finance"] = "general",
    include_raw_content: bool = False,
):
    """Run a web search"""
    return tavily_client.search(
        query,
        max_results=max_results,
        include_raw_content=include_raw_content,
        topic=topic,
    )


# System prompt to steer the agent to be an expert researcher
research_instructions = """You are an expert researcher. Your job is to conduct thorough research, and then write a polished report.

You have access to an internet search tool as your primary means of gathering information.

## `internet_search`

Use this to run an internet search for a given query. You can specify the max number of results to return, the topic, and whether raw content should be included.
"""

# Create the deep agent
agent = create_deep_agent(
    tools=[internet_search],
    system_prompt=research_instructions,
)

# Invoke the agent
result = agent.invoke({"messages": [{"role": "user", "content": "What is langgraph?"}]})
```

See [examples/research/research_agent.py](examples/research/research_agent.py) for a more complex example.

The agent created with `create_deep_agent` is just a LangGraph graph - so you can interact with it (streaming, human-in-the-loop, memory, studio)
in the same way you would any LangGraph agent.

## æ ¸å¿ƒåŠŸèƒ½

**ğŸ“‹ è§„åˆ’ä¸ä»»åŠ¡åˆ†è§£**

Deep Agents å†…ç½® `write_todos` å·¥å…·ï¼Œä½¿ä»£ç†èƒ½å¤Ÿå°†å¤æ‚ä»»åŠ¡åˆ†è§£ä¸ºç¦»æ•£æ­¥éª¤ï¼Œè·Ÿè¸ªè¿›åº¦ï¼Œå¹¶æ ¹æ®æ–°ä¿¡æ¯è°ƒæ•´è®¡åˆ’ã€‚

**ğŸ—‚ï¸ ä¸Šä¸‹æ–‡ç®¡ç†**

æ–‡ä»¶ç³»ç»Ÿå·¥å…·ï¼ˆ`ls`ã€`read_file`ã€`write_file`ã€`edit_file`ã€`glob`ã€`grep`ï¼‰å…è®¸ä»£ç†å°†å¤§å‹ä¸Šä¸‹æ–‡å¸è½½åˆ°å†…å­˜ï¼Œé˜²æ­¢ä¸Šä¸‹æ–‡çª—å£æº¢å‡ºï¼Œå¹¶èƒ½å¤Ÿå¤„ç†å¯å˜é•¿åº¦çš„å·¥å…·ç»“æœã€‚

**ğŸ”„ å­ä»£ç†ç”Ÿæˆ**

å†…ç½® `task` å·¥å…·ä½¿ä»£ç†èƒ½å¤Ÿç”Ÿæˆä¸“é—¨çš„å­ä»£ç†è¿›è¡Œä¸Šä¸‹æ–‡éš”ç¦»ã€‚è¿™ä¿æŒäº†ä¸»ä»£ç†ä¸Šä¸‹æ–‡çš„æ¸…æ´ï¼ŒåŒæ—¶ä»èƒ½æ·±å…¥å¤„ç†ç‰¹å®šå­ä»»åŠ¡ã€‚

**ğŸ’¾ é•¿æœŸè®°å¿†**

ä½¿ç”¨ LangGraph çš„ Store æ‰©å±•è·¨çº¿ç¨‹çš„æŒä¹…è®°å¿†ã€‚ä»£ç†å¯ä»¥ä¿å­˜å’Œæ£€ç´¢ä¹‹å‰å¯¹è¯ä¸­çš„ä¿¡æ¯ã€‚

## æ¸¯è‚¡ä¸“ç”¨åŠŸèƒ½

**ğŸ“„ PDF è§£æå¼•æ“**
- æ™ºèƒ½è¯†åˆ«æ¸¯äº¤æ‰€å…¬å‘Šæ ¼å¼
- æå–è´¢åŠ¡æ•°æ®ã€äº¤æ˜“ä¿¡æ¯ç­‰å…³é”®å†…å®¹
- æ”¯æŒç¹ä½“ä¸­æ–‡å’Œè‹±æ–‡æ–‡æ¡£

**ğŸ” æ™ºèƒ½æ‘˜è¦ç”Ÿæˆ**
- è‡ªåŠ¨è¯†åˆ«å…¬å‘Šç±»å‹å’Œé‡è¦æ€§
- ç”Ÿæˆç»“æ„åŒ–æ‘˜è¦å’Œå¸‚åœºå½±å“åˆ†æ
- æ”¯æŒè‡ªå®šä¹‰æ‘˜è¦æ¨¡æ¿

**ğŸ“Š æ•°æ®æå–ä¸ç»“æ„åŒ–**
- è´¢åŠ¡æŒ‡æ ‡è‡ªåŠ¨æå–
- å…¬å¸è¡ŒåŠ¨ä¿¡æ¯è¯†åˆ«
- å¸‚åœºäº‹ä»¶åˆ†ç±»æ ‡æ³¨

**âš¡ ç¼“å­˜ä¼˜åŒ–**
- PDF æ–‡æ¡£ç¼“å­˜æœºåˆ¶
- æ‘˜è¦ç»“æœæŒä¹…åŒ–å­˜å‚¨
- å¢é‡æ›´æ–°æ”¯æŒ

**ğŸŒˆ ç”¨æˆ·ä½“éªŒä¼˜åŒ–**
- ASCIIè‰ºæœ¯å­—æ¨ªå¹… (571ç§å­—ä½“å¯é€‰)
- å½©è™¹æ¸å˜æ•ˆæœ (7è‰²å¾ªç¯æ˜¾ç¤º)
- å±…ä¸­å¯¹é½çš„å¯åŠ¨æ—¥å¿—
- è‡ªå®šä¹‰ä¸»é¢˜é¢œè‰²æ”¯æŒ

## é¡¹ç›®ç»“æ„

```
deepagents-hk/
â”œâ”€â”€ libs/
â”‚   â”œâ”€â”€ deepagents/          # DeepAgentsæ¡†æ¶æ ¸å¿ƒ
â”‚   â”‚   â”œâ”€â”€ graph.py         # Agentå›¾æ„å»º
â”‚   â”‚   â”œâ”€â”€ backends/        # å­˜å‚¨åç«¯
â”‚   â”‚   â””â”€â”€ middleware/      # ä¸­é—´ä»¶
â”‚   â””â”€â”€ deepagents-cli/      # DeepAgents CLIå·¥å…·
â”œâ”€â”€ src/                     # HKEXåº”ç”¨ä»£ç  (ä½œä¸ºsrcåŒ…)
â”‚   â”œâ”€â”€ agents/              # ä»£ç†æ ¸å¿ƒé€»è¾‘
â”‚   â”‚   â”œâ”€â”€ main_agent.py    # ä¸»ä»£ç†
â”‚   â”‚   â””â”€â”€ subagents.py     # å­ä»£ç†å®šä¹‰
â”‚   â”œâ”€â”€ api/                 # API æ¥å£
â”‚   â”‚   â””â”€â”€ client.py        # å®¢æˆ·ç«¯
â”‚   â”œâ”€â”€ cli/                 # å‘½ä»¤è¡Œå·¥å…· (src.cliåŒ…)
â”‚   â”‚   â”œâ”€â”€ config.py        # é…ç½®å’Œæ¨¡å‹åˆ›å»º
â”‚   â”‚   â”œâ”€â”€ main.py          # ä¸»å…¥å£
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ config/              # é…ç½®æ¨¡å—
â”‚   â”‚   â””â”€â”€ agent_config.py  # Agentæ¨¡å‹é…ç½®
â”‚   â”œâ”€â”€ services/            # ä¸šåŠ¡æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ hkex_api.py      # æ¸¯äº¤æ‰€ API
â”‚   â”‚   â””â”€â”€ pdf_parser.py    # PDF è§£ææœåŠ¡
â”‚   â”œâ”€â”€ tools/               # å·¥å…·é›†åˆ
â”‚   â”‚   â”œâ”€â”€ hkex_tools.py    # æ¸¯è‚¡ä¸“ç”¨å·¥å…·
â”‚   â”‚   â”œâ”€â”€ pdf_tools.py     # PDF å¤„ç†å·¥å…·
â”‚   â”‚   â””â”€â”€ summary_tools.py # æ‘˜è¦å·¥å…·
â”‚   â””â”€â”€ prompts/             # æç¤ºè¯æ¨¡æ¿
â”‚       â”œâ”€â”€ main_system_prompt.md
â”‚       â””â”€â”€ pdf_analyzer_prompt.md
â”œâ”€â”€ pdf_cache/               # PDF ç¼“å­˜ç›®å½• (å·² gitignore)
â”‚   â””â”€â”€ {stock_code}/        # æŒ‰è‚¡ç¥¨ä»£ç åˆ†ç±»
â”‚       â”œâ”€â”€ {date}-{title}.pdf      # PDF æ–‡ä»¶
â”‚       â”œâ”€â”€ {date}-{title}.txt      # æ–‡æœ¬ç¼“å­˜ (å¤§å‹ PDF)
â”‚       â””â”€â”€ {date}-{title}_tables.json  # è¡¨æ ¼ç¼“å­˜ (å¤§å‹ PDF)
â”œâ”€â”€ md/                      # æ‘˜è¦å­˜å‚¨ç›®å½• (å·² gitignore)
â”œâ”€â”€ docs/                    # é¡¹ç›®æ–‡æ¡£
â”œâ”€â”€ .env                     # ç¯å¢ƒå˜é‡é…ç½®
â”œâ”€â”€ pyproject.toml           # ç»Ÿä¸€é¡¹ç›®é…ç½®
â””â”€â”€ README.md                # é¡¹ç›®è¯´æ˜
```

**é‡è¦è¯´æ˜**ï¼š
- é¡¹ç›®å·²ç»Ÿä¸€åˆ°å•ä¸€ `pyproject.toml` é…ç½®
- `src` ç›®å½•ä½œä¸ºå®Œæ•´çš„PythonåŒ…ï¼Œæ‰€æœ‰æ¨¡å—ä½¿ç”¨ `from src.xxx` å¯¼å…¥
- `hkex` å‘½ä»¤entry point: `src.cli.main:cli_main`
- æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ä¸åŒLLMæ¨¡å‹å’Œå‚æ•°

## å¼€å‘æŒ‡å—

### ç¯å¢ƒè®¾ç½®

```bash
# å…‹éš†é¡¹ç›®
git clone <repository-url>
cd deepagents-hk

# å®‰è£…ä¾èµ–
uv sync

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate  # Linux/Mac
# æˆ–
.venv\Scripts\activate     # Windows
```

### è¿è¡Œæµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_pdf_parser.py

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=src tests/
```

### ä»£ç è§„èŒƒ

æœ¬é¡¹ç›®ä½¿ç”¨ä»¥ä¸‹å·¥å…·ç¡®ä¿ä»£ç è´¨é‡ï¼š

- **Ruff**: ä»£ç æ£€æŸ¥å’Œæ ¼å¼åŒ–
- **MyPy**: ç±»å‹æ£€æŸ¥
- **Black**: ä»£ç æ ¼å¼åŒ–

```bash
# è¿è¡Œä»£ç æ£€æŸ¥
ruff check src/
mypy src/

# æ ¼å¼åŒ–ä»£ç 
ruff format src/
black src/
```

## è‡ªå®šä¹‰ Deep Agents

### `model`

By default, `deepagents` uses `"claude-sonnet-4-5-20250929"`. You can customize this by passing any [LangChain model object](https://python.langchain.com/docs/integrations/chat/).

```python
from langchain.chat_models import init_chat_model
from deepagents import create_deep_agent

model = init_chat_model("openai:gpt-4o")
agent = create_deep_agent(
    model=model,
)
```

### `system_prompt`
Deep Agents come with a built-in system prompt. This is relatively detailed prompt that is heavily based on and inspired by [attempts](https://github.com/kn1026/cc/blob/main/claudecode.md) to [replicate](https://github.com/asgeirtj/system_prompts_leaks/blob/main/Anthropic/claude-code.md)
Claude Code's system prompt. It was made more general purpose than Claude Code's system prompt. The default prompt contains detailed instructions for how to use the built-in planning tool, file system tools, and sub agents.

Each deep agent tailored to a use case should include a custom system prompt specific to that use case as well. The importance of prompting for creating a successful deep agent cannot be overstated.

```python
from deepagents import create_deep_agent

research_instructions = """You are an expert researcher. Your job is to conduct thorough research, and then write a polished report.
"""

agent = create_deep_agent(
    system_prompt=research_instructions,
)
```

### `tools`

Just like with tool-calling agents, you can provide a deep agent with a set of tools that it has access to.

```python
import os
from typing import Literal
from tavily import TavilyClient
from deepagents import create_deep_agent

tavily_client = TavilyClient(api_key=os.environ["TAVILY_API_KEY"])

def internet_search(
    query: str,
    max_results: int = 5,
    topic: Literal["general", "news", "finance"] = "general",
    include_raw_content: bool = False,
):
    """Run a web search"""
    return tavily_client.search(
        query,
        max_results=max_results,
        include_raw_content=include_raw_content,
        topic=topic,
    )

agent = create_deep_agent(
    tools=[internet_search]
)
```

### `middleware`
`create_deep_agent` is implemented with middleware that can be customized. You can provide additional middleware to extend functionality, add tools, or implement custom hooks. 

```python
from langchain_core.tools import tool
from deepagents import create_deep_agent
from langchain.agents.middleware import AgentMiddleware

@tool
def get_weather(city: str) -> str:
    """Get the weather in a city."""
    return f"The weather in {city} is sunny."

@tool
def get_temperature(city: str) -> str:
    """Get the temperature in a city."""
    return f"The temperature in {city} is 70 degrees Fahrenheit."

class WeatherMiddleware(AgentMiddleware):
  tools = [get_weather, get_temperature]

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    middleware=[WeatherMiddleware()]
)
```

### `subagents`

A main feature of Deep Agents is their ability to spawn subagents. You can specify custom subagents that your agent can hand off work to in the subagents parameter. Sub agents are useful for context quarantine (to help not pollute the overall context of the main agent) as well as custom instructions.

`subagents` should be a list of dictionaries, where each dictionary follow this schema:

```python
class SubAgent(TypedDict):
    name: str
    description: str
    prompt: str
    tools: Sequence[BaseTool | Callable | dict[str, Any]]
    model: NotRequired[str | BaseChatModel]
    middleware: NotRequired[list[AgentMiddleware]]
    interrupt_on: NotRequired[dict[str, bool | InterruptOnConfig]]

class CompiledSubAgent(TypedDict):
    name: str
    description: str
    runnable: Runnable
```

**SubAgent fields:**
- **name**: This is the name of the subagent, and how the main agent will call the subagent
- **description**: This is the description of the subagent that is shown to the main agent
- **prompt**: This is the prompt used for the subagent
- **tools**: This is the list of tools that the subagent has access to.
- **model**: Optional model name or model instance.
- **middleware** Additional middleware to attach to the subagent. See [here](https://docs.langchain.com/oss/python/langchain/middleware) for an introduction into middleware and how it works with create_agent.
- **interrupt_on** A custom interrupt config that specifies human-in-the-loop interactions for your tools.

**CompiledSubAgent fields:**
- **name**: This is the name of the subagent, and how the main agent will call the subagent
- **description**: This is the description of the subagent that is shown to the main agent  
- **runnable**: A pre-built LangGraph graph/agent that will be used as the subagent

#### Using SubAgent

```python
import os
from typing import Literal
from tavily import TavilyClient
from deepagents import create_deep_agent

tavily_client = TavilyClient(api_key=os.environ["TAVILY_API_KEY"])

def internet_search(
    query: str,
    max_results: int = 5,
    topic: Literal["general", "news", "finance"] = "general",
    include_raw_content: bool = False,
):
    """Run a web search"""
    return tavily_client.search(
        query,
        max_results=max_results,
        include_raw_content=include_raw_content,
        topic=topic,
    )

research_subagent = {
    "name": "research-agent",
    "description": "Used to research more in depth questions",
    "system_prompt": "You are a great researcher",
    "tools": [internet_search],
    "model": "openai:gpt-4o",  # Optional override, defaults to main agent model
}
subagents = [research_subagent]

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    subagents=subagents
)
```

#### Using CustomSubAgent

For more complex use cases, you can provide your own pre-built LangGraph graph as a subagent:

```python
# Create a custom agent graph
custom_graph = create_agent(
    model=your_model,
    tools=specialized_tools,
    prompt="You are a specialized agent for data analysis..."
)

# Use it as a custom subagent
custom_subagent = CompiledSubAgent(
    name="data-analyzer",
    description="Specialized agent for complex data analysis tasks",
    runnable=custom_graph
)

subagents = [custom_subagent]

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    tools=[internet_search],
    system_prompt=research_instructions,
    subagents=subagents
)
```

### `interrupt_on`
A common reality for agents is that some tool operations may be sensitive and require human approval before execution. Deep Agents supports human-in-the-loop workflows through LangGraphâ€™s interrupt capabilities. You can configure which tools require approval using a checkpointer.

These tool configs are passed to our prebuilt [HITL middleware](https://docs.langchain.com/oss/python/langchain/middleware#human-in-the-loop) so that the agent pauses execution and waits for feedback from the user before executing configured tools.

```python
from langchain_core.tools import tool
from deepagents import create_deep_agent

@tool
def get_weather(city: str) -> str:
    """Get the weather in a city."""
    return f"The weather in {city} is sunny."

agent = create_deep_agent(
    model="anthropic:claude-sonnet-4-20250514",
    tools=[get_weather],
    interrupt_on={
        "get_weather": {
            "allowed_decisions": ["approve", "edit", "reject"]
        },
    }
)

```

## Deep Agents Middleware

Deep Agents are built with a modular middleware architecture. As a reminder, Deep Agents have access to:
- A planning tool
- A filesystem for storing context and long-term memories
- The ability to spawn subagents

Each of these features is implemented as separate middleware. When you create a deep agent with `create_deep_agent`, we automatically attach **TodoListMiddleware**, **FilesystemMiddleware** and **SubAgentMiddleware** to your agent.

Middleware is a composable concept, and you can choose to add as many or as few middleware to an agent depending on your use case. That means that you can also use any of the aforementioned middleware independently!

### TodoListMiddleware

Planning is integral to solving complex problems. If youâ€™ve used claude code recently, youâ€™ll notice how it writes out a To-Do list before tackling complex, multi-part tasks. Youâ€™ll also notice how it can adapt and update this To-Do list on the fly as more information comes in.

**TodoListMiddleware** provides your agent with a tool specifically for updating this To-Do list. Before, and while it executes a multi-part task, the agent is prompted to use the write_todos tool to keep track of what its doing, and what still needs to be done.

```python
from langchain.agents import create_agent
from langchain.agents.middleware import TodoListMiddleware

# TodoListMiddleware is included by default in create_deep_agent
# You can customize it if building a custom agent
agent = create_agent(
    model="anthropic:claude-sonnet-4-20250514",
    # Custom planning instructions can be added via middleware
    middleware=[
        TodoListMiddleware(
            system_prompt="Use the write_todos tool to..."  # Optional: Custom addition to the system prompt
        ),
    ],
)
```

### FilesystemMiddleware

Context engineering is one of the main challenges in building effective agents. This can be particularly hard when using tools that can return variable length results (ex. web_search, rag), as long ToolResults can quickly fill up your context window.
**FilesystemMiddleware** provides four tools to your agent to interact with both short-term and long-term memory.
- **ls**: List the files in your filesystem
- **read_file**: Read an entire file, or a certain number of lines from a file
- **write_file**: Write a new file to your filesystem
- **edit_file**: Edit an existing file in your filesystem

```python
from langchain.agents import create_agent
from deepagents.middleware.filesystem import FilesystemMiddleware


# FilesystemMiddleware is included by default in create_deep_agent
# You can customize it if building a custom agent
agent = create_agent(
    model="anthropic:claude-sonnet-4-20250514",
    middleware=[
        FilesystemMiddleware(
            backend=..., # Optional: customize storage backend
            system_prompt="Write to the filesystem when...",  # Optional custom system prompt override
            custom_tool_descriptions={
                "ls": "Use the ls tool when...",
                "read_file": "Use the read_file tool to..."
            }  # Optional: Custom descriptions for filesystem tools
        ),
    ],
)
```

### SubAgentMiddleware

Handing off tasks to subagents is a great way to isolate context, keeping the context window of the main (supervisor) agent clean while still going deep on a task. The subagents middleware allows you supply subagents through a task tool.

A subagent is defined with a name, description, system prompt, and tools. You can also provide a subagent with a custom model, or with additional middleware. This can be particularly useful when you want to give the subagent an additional state key to share with the main agent.

```python
from langchain_core.tools import tool
from langchain.agents import create_agent
from deepagents.middleware.subagents import SubAgentMiddleware


@tool
def get_weather(city: str) -> str:
    """Get the weather in a city."""
    return f"The weather in {city} is sunny."

agent = create_agent(
    model="claude-sonnet-4-20250514",
    middleware=[
        SubAgentMiddleware(
            default_model="claude-sonnet-4-20250514",
            default_tools=[],
            subagents=[
                {
                    "name": "weather",
                    "description": "This subagent can get weather in cities.",
                    "system_prompt": "Use the get_weather tool to get the weather in a city.",
                    "tools": [get_weather],
                    "model": "gpt-4.1",
                    "middleware": [],
                }
            ],
        )
    ],
)
```

For more complex use cases, you can also provide your own pre-built LangGraph graph as a subagent.

```python
# Create a custom LangGraph graph
def create_weather_graph():
    workflow = StateGraph(...)
    # Build your custom graph
    return workflow.compile()

weather_graph = create_weather_graph()

# Wrap it in a CompiledSubAgent
weather_subagent = CompiledSubAgent(
    name="weather",
    description="This subagent can get weather in cities.",
    runnable=weather_graph
)

agent = create_agent(
    model="anthropic:claude-sonnet-4-20250514",
    middleware=[
        SubAgentMiddleware(
            default_model="claude-sonnet-4-20250514",
            default_tools=[],
            subagents=[weather_subagent],
        )
    ],
)
```

## Sync vs Async

Prior versions of deepagents separated sync and async agent factories. 

`async_create_deep_agent` has been folded in to `create_deep_agent`.

**You should use `create_deep_agent` as the factory for both sync and async agents**


## MCP

The `deepagents` library can be ran with MCP tools. This can be achieved by using the [Langchain MCP Adapter library](https://github.com/langchain-ai/langchain-mcp-adapters).

**NOTE:** You will want to use `from deepagents import async_create_deep_agent` to use the async version of `deepagents`, since MCP tools are async

(To run the example below, will need to `pip install langchain-mcp-adapters`)

```python
import asyncio
from langchain_mcp_adapters.client import MultiServerMCPClient
from deepagents import create_deep_agent

async def main():
    # Collect MCP tools
    mcp_client = MultiServerMCPClient(...)
    mcp_tools = await mcp_client.get_tools()

    # Create agent
    agent = create_deep_agent(tools=mcp_tools, ....)

    # Stream the agent
    async for chunk in agent.astream(
        {"messages": [{"role": "user", "content": "what is langgraph?"}]},
        stream_mode="values"
    ):
        if "messages" in chunk:
            chunk["messages"][-1].pretty_print()

asyncio.run(main())
```

## ğŸ“„ PDF æ™ºèƒ½æˆªæ–­åŠŸèƒ½

### åŠŸèƒ½æ¦‚è¿°

ä¸ºäº†é˜²æ­¢å¤§å‹ PDFï¼ˆå¦‚å¹´æŠ¥ï¼‰å¯¼è‡´ LLM token æº¢å‡ºï¼Œç³»ç»Ÿå®ç°äº†æ™ºèƒ½æˆªæ–­æœºåˆ¶ï¼š

- **è‡ªåŠ¨æ£€æµ‹**ï¼šå¯¹äºæ–‡æœ¬ > 50k å­—ç¬¦æˆ–è¡¨æ ¼ > 200 è¡Œçš„ PDFï¼Œè‡ªåŠ¨è§¦å‘æˆªæ–­
- **å®Œæ•´ä¿ç•™**ï¼šå…¨éƒ¨å†…å®¹ä¿å­˜åˆ°ç¼“å­˜æ–‡ä»¶ï¼ˆ`.txt` å’Œ `_tables.json`ï¼‰
- **é¢„è§ˆè¿”å›**ï¼šå·¥å…·è¿”å›å‰ 5k å­—ç¬¦æ–‡æœ¬é¢„è§ˆ + å‰ 5 ä¸ªè¡¨æ ¼
- **æ¸…æ™°æŒ‡å¼•**ï¼šé¢„è§ˆä¸­åŒ…å«å®Œæ•´è·¯å¾„å’Œ `read_file()` ä½¿ç”¨è¯´æ˜

### å·¥ä½œåŸç†

```python
# 1. æå– PDF å†…å®¹ï¼ˆè‡ªåŠ¨æˆªæ–­ï¼‰
pdf_content = extract_pdf_content("path/to/large_annual_report.pdf")

# 2. æ£€æŸ¥æ˜¯å¦è¢«æˆªæ–­
if pdf_content["truncated"]:
    print(f"é¢„è§ˆæ–‡æœ¬: {pdf_content['text'][:100]}...")
    print(f"å®Œæ•´æ–‡æœ¬è·¯å¾„: {pdf_content['text_path']}")
    print(f"å®Œæ•´è¡¨æ ¼è·¯å¾„: {pdf_content['tables_path']}")
    
    # 3. æŒ‰éœ€è¯»å–å®Œæ•´å†…å®¹
    full_text = read_file(pdf_content["text_path"])
    full_tables = json.loads(read_file(pdf_content["tables_path"]))
else:
    # å°æ–‡æ¡£ï¼šç›´æ¥ä½¿ç”¨å…¨æ–‡
    full_text = pdf_content["text"]
    full_tables = pdf_content["tables"]
```

### é˜ˆå€¼é…ç½®

é»˜è®¤é˜ˆå€¼ï¼ˆå¯åœ¨ `src/tools/pdf_tools.py` ä¸­è°ƒæ•´ï¼‰ï¼š

```python
MAX_INLINE_TEXT_CHARS = 50_000  # 50k å­—ç¬¦ â‰ˆ 12.5k tokens
MAX_INLINE_TABLE_ROWS = 200     # è¡¨æ ¼æ€»è¡Œæ•°é™åˆ¶
TEXT_PREVIEW_CHARS = 5_000      # é¢„è§ˆé•¿åº¦
TABLE_PREVIEW_COUNT = 5         # é¢„è§ˆè¡¨æ ¼æ•°é‡
```

### ç¼“å­˜æ–‡ä»¶ç»“æ„

```
pdf_cache/
â””â”€â”€ 03800/
    â”œâ”€â”€ 2025-04-29-2024å¹´æŠ¥.pdf           # åŸå§‹ PDF
    â”œâ”€â”€ 2025-04-29-2024å¹´æŠ¥.txt           # æ–‡æœ¬ç¼“å­˜ï¼ˆå¤§å‹ PDFï¼‰
    â””â”€â”€ 2025-04-29-2024å¹´æŠ¥_tables.json   # è¡¨æ ¼ç¼“å­˜ï¼ˆJSON æ ¼å¼ï¼‰
```

### å‘åå…¼å®¹æ€§

- **å°å‹ PDF**ï¼ˆ< 50k å­—ç¬¦ï¼‰ï¼šè¡Œä¸ºå®Œå…¨ä¸å˜ï¼Œè¿”å›ç»“æ„ä¸ç°æœ‰ä¸€è‡´
- **å¤§å‹ PDF**ï¼šæ–°å¢ `truncated`ã€`text_path`ã€`tables_path` å­—æ®µï¼Œä¸å½±å“ç°æœ‰ä»£ç 

### æ€§èƒ½ä¼˜åŒ–

- **å»¶è¿Ÿå†™å…¥**ï¼šä»…æˆªæ–­æ—¶æ‰å†™ç¼“å­˜ï¼Œå°æ–‡æ¡£é›¶å¼€é”€
- **åŸå­å†™å…¥**ï¼šä¸´æ—¶æ–‡ä»¶ + é‡å‘½åï¼Œé˜²æ­¢å¹¶å‘è¯»å–ä¸å®Œæ•´æ•°æ®
- **è‡ªåŠ¨æ¸…ç†**ï¼š`cleanup_old_pdfs()` åŒæ—¶æ¸…ç† PDF å’Œç¼“å­˜æ–‡ä»¶

### æµ‹è¯•éªŒè¯

```bash
# è¿è¡Œ PDF æˆªæ–­åŠŸèƒ½æµ‹è¯•
pytest libs/deepagents/tests/unit_tests/test_pdf_truncation.py -v
pytest libs/deepagents/tests/integration_tests/test_pdf_truncation_workflow.py -v
```
